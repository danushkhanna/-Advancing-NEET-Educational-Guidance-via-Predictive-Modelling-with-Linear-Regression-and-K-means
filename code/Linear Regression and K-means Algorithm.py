
# -*- coding: utf-8 -*-
"""Enhancing Educational Guidance for NEET Aspirants: Integrating Predictive Modelling for Rank Estimation and College Clustering using Linear Regression and K-means Algorithm

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fBTewzC2mjsoZaaUoeAIq5MrEJn9-6Gr
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('/content/New Score-Rank.csv')

df_null = df[df['Expected Score'].isnull()]
df_new = df[df['Expected Score'].notnull()]
df_null.fillna("",inplace=True)
df_null

X = df_new.iloc[:, 1:-1].values
y = df_new.iloc[:, -1].values
X_null = df_null.iloc[:, 1:-1].values
y_null = df_null.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, random_state = 0)

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
model = regressor.fit(X_train, y_train)
y_null_predict = model.predict(X_null)

df_null['Expected Score'] = y_null_predict
df_null

# Concatenate the DataFrame and Series
df_newfull = pd.concat([df_new, df_null])

df_newfull

plt.scatter(X_train, y_train, color = 'red')
plt.plot(X_train,model.predict(X_train), color = 'blue')
plt.title('Linear Regression Prediction (Training set)')
plt.xlabel('NEET Rank')
plt.ylabel('Expected Score')
plt.show()

dfscore=pd.read_csv("/content/Merged_data.csv")

dfscore

plt.figure(figsize=(10, 6))
cluster_avg_attrition = dfscore.groupby('Cluster')['Attrition %'].mean().sort_values(ascending=False)
cluster_avg_attrition.plot(kind='bar')
plt.xlabel('Cluster')
plt.ylabel('Average Attrition %')
plt.title('Average Attrition % by Cluster')
plt.xticks(rotation=0)
plt.show()

top_colleges = dfscore.nlargest(10, 'Attraction Index')
plt.barh(top_colleges['College name in college and course sheet 2023'], top_colleges['Attraction Index'])
plt.xlabel('Attraction Index')
plt.ylabel('College')
plt.title('Top Colleges by Attraction Index')
plt.gca().invert_yaxis()
plt.show()

import matplotlib.pyplot as plt

state_counts = dfscore['STATE'].value_counts().sort_values(ascending=False)
colors = plt.cm.tab20c.colors[:len(state_counts)]

plt.figure(figsize=(12, 6))
bars = plt.bar(state_counts.index, state_counts.values, color=colors)
plt.xlabel('State')
plt.ylabel('Number of Students')
plt.title('State-wise Distribution of Students')
plt.xticks(rotation=90)

# Adding a legend with color explanations
legend_labels = [f'{state}: {count}' for state, count in zip(state_counts.index, state_counts.values)]
plt.legend(bars, legend_labels, title='State Counts', loc='upper right', bbox_to_anchor=(1.1, 1))

plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=dfscore, x='STATE', y='Attrition %')
plt.xlabel('State')
plt.ylabel('Attrition %')
plt.title('Attrition % by State')
plt.xticks(rotation=90)
plt.show()

# Calculate summary statistics
mean_expected_score = df_newfull['Expected Score'].mean()
median_expected_score = df_newfull['Expected Score'].median()
std_expected_score = df_newfull['Expected Score'].std()
min_expected_score = df_newfull['Expected Score'].min()
max_expected_score = df_newfull['Expected Score'].max()

# Display summary statistics
print(f"Mean Expected Score: {mean_expected_score}")
print(f"Median Expected Score: {median_expected_score}")
print(f"Standard Deviation of Expected Score: {std_expected_score}")
print(f"Minimum Expected Score: {min_expected_score}")
print(f"Maximum Expected Score: {max_expected_score}")

# Box plot for Expected Score
plt.figure(figsize=(8, 6))
plt.boxplot(df_newfull['Expected Score'])
plt.title('Box Plot of Expected Score')
plt.ylabel('Expected Score')
plt.show()

# Calculate quartiles
q25 = df_newfull['Expected Score'].quantile(0.25)
q75 = df_newfull['Expected Score'].quantile(0.75)

# Display quartiles
print(f"25th Percentile (Q1): {q25}")
print(f"75th Percentile (Q3): {q75}")

# Import necessary library
from sklearn.metrics import r2_score

y_val_pred = model.predict(X_val)

# Calculate R-squared for validation
r2_val = r2_score(y_val, y_val_pred)
print(f"R-squared for validation: {r2_val:.4f}")

# Plot the validated results
plt.scatter(X_val, y_val, color='red', label='Actual Data')
plt.plot(X_val, y_val_pred, color='blue', label='Predicted Data')
plt.title('Linear Regression Prediction (Validation)')
plt.xlabel('NEET Rank')
plt.ylabel('Expected Score')
plt.legend()
plt.show()

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

collegelist = pd.read_csv("/content/Merged_data.csv")

collegelist.shape

collegelist.head()

collegelist.tail()

filtered_df = collegelist[collegelist['Allotted Quota'] == 'All India']

filtered_df.shape

filtered_df.tail()

filtered_df.head()

reset_df = filtered_df.reset_index(drop=True)

reset_df

reset_df = reset_df[reset_df['CAT'] == 'OP NO']

reset_df = reset_df.reset_index(drop=True)

reset_df.head()

selected_columns = ['College name in college and course sheet 2023', 'STATE', 'Allotted Quota', 'CAT', 'R1 Closing', 'Attrition %']

new_df = reset_df[selected_columns]

new_df

unique_values = new_df['STATE'].unique()
print(unique_values)

df_with_r1closing = new_df[new_df['R1 Closing'].notnull()]

df_without_r1closing = new_df[new_df['R1 Closing'].isnull()]

df_with_r1closing

df_without_r1closing.fillna('0',inplace=True)

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Assuming your DataFrame is called 'df' with columns 'College name', 'STATE', 'R1 Closing', and 'Attrition %'

# Select the columns for clustering
columns_for_clustering = ['R1 Closing', 'Attrition %']

# Determine the optimal number of clusters using the elbow method or silhouette score
wcss = []
silhouette_scores = []
max_clusters = min(10, len(df_with_r1closing) - 1)  # Set the maximum number of clusters based on the size of the dataset

for num_clusters in range(2, max_clusters + 1):
    kmeans = KMeans(n_clusters=num_clusters, random_state=42)
    kmeans.fit(df_with_r1closing[columns_for_clustering])
    wcss.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(df_with_r1closing[columns_for_clustering], kmeans.labels_))

# Plot the elbow curve
plt.plot(range(2, max_clusters + 1), wcss, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.title('Elbow Curve')
plt.show()

# Plot the silhouette scores
plt.plot(range(2, max_clusters + 1), silhouette_scores, marker='o')
plt.xlabel('Number of Clusters')
plt.ylabel('Silhouette Score')
plt.title('Silhouette Score')
plt.show()

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# Assuming your DataFrame is called 'df_with_r1closing' and contains the necessary columns

# Select the columns for clustering
columns_for_clustering = ['R1 Closing', 'Attrition %']

# Perform K-means clustering
num_clusters = 2  # Adjust the number of clusters as per your requirements
kmeans = KMeans(n_clusters=num_clusters, random_state=42)
kmeans.fit(df_with_r1closing[columns_for_clustering])

# Assign the cluster labels to the DataFrame
df_with_r1closing['Cluster'] = kmeans.labels_

# Calculate the attraction index
df_with_r1closing['Attraction Index'] = df_with_r1closing.groupby('Cluster')['R1 Closing'].rank(ascending=True, method='min', na_option='bottom')

# Calculate and print the silhouette score
silhouette_avg = silhouette_score(df_with_r1closing[columns_for_clustering], kmeans.labels_)
print(f"Silhouette Score: {silhouette_avg:.2f}")

df_with_r1closing

import pandas as pd

# Define the state priority based on your requirements
state_priority = {
    'Delhi': 1,
    'Uttar Pradesh': 2,
    'Rajasthan': 3,
    'Uttarakhand': 4,
    'Himachal Pradesh': 5,
    'Punjab': 6,
    'Jammu And Kashmir': 7,
    'Madhya Pradesh': 8,
    'Gujarat': 9,
    'Bihar': 10,
    'Jharkhand': 11,
    'Chhattisgarh': 12,
    'Karnataka': 13,
    'Kerala': 14,
    'Maharashtra': 15,
    'Odisha': 16,
    'Tamil Nadu': 17,
    'Telangana': 18,
    'Andhra Pradesh': 19,
    'Chandigarh': 20,
    'West Bengal': 21,
    'Haryana': 22,
    'Goa': 23,
    'Manipur': 24,
    'Assam': 25,
    'Puducherry': 26,
    'Meghalaya': 27,
    'Dadra And Nagar Haveli': 28,
    'Andaman And Nicobar Islands': 29,
    'Tripura': 30,
    'Arunachal Pradesh': 31,
    'Mizoram': 32
}

# Create a new column 'Attraction Index' based on the state priority
df_with_r1closing['Attraction Index_State'] = df_with_r1closing['STATE'].map(state_priority)
df_with_r1closing['Attraction Index_State'].fillna(0, inplace=True)

# Print the selected columns to observe the changes in attraction index
print(df_with_r1closing[['College name in college and course sheet 2023', 'R1 Closing', 'Attrition %', 'Attraction Index_State']])

df_with_r1closing

df_with_r1closing['Sum'] = df_with_r1closing['Attraction Index'] + df_with_r1closing['Attraction Index_State']

df_with_r1closing

df_with_r1closing.drop(['Attraction Index', 'Attraction Index_State'], axis=1, inplace=True)

df_with_r1closing.rename(columns={'Sum': 'Attraction Index'}, inplace=True)

df_with_r1closing

merged_df = pd.concat([df_with_r1closing, df_without_r1closing], ignore_index=True)



# Print the merged and sorted DataFrame
print(merged_df)

merged_df.to_csv("Merged_data.csv")

merged_df.sort_values(by='Attraction Index', ascending=True, inplace=True)

merged_df

# Calculate the statistics for the "R1 Closing" column
mean_r1_closing = df_with_r1closing['R1 Closing'].mean()
std_r1_closing = df_with_r1closing['R1 Closing'].std()
min_r1_closing = df_with_r1closing['R1 Closing'].min()
max_r1_closing = df_with_r1closing['R1 Closing'].max()

# Display the calculated statistics
print(f"Mean R1 Closing: {mean_r1_closing}")
print(f"Standard Deviation of R1 Closing: {std_r1_closing}")
print(f"Minimum R1 Closing: {min_r1_closing}")
print(f"Maximum R1 Closing: {max_r1_closing}")

# Calculate the statistics for the "Attrition %" column
mean_attrition = df_with_r1closing['Attrition %'].mean()
std_attrition = df_with_r1closing['Attrition %'].std()
min_attrition = df_with_r1closing['Attrition %'].min()
max_attrition = df_with_r1closing['Attrition %'].max()

# Display the calculated statistics
print(f"Mean Attrition %: {mean_attrition}")
print(f"Standard Deviation of Attrition %: {std_attrition}")
print(f"Minimum Attrition %: {min_attrition}")
print(f"Maximum Attrition %: {max_attrition}")

# Calculate the statistics for the "Cluster" column
mean_cluster = df_with_r1closing['Cluster'].mean()

# Display the calculated statistics
print(f"Mean Cluster: {mean_cluster}")

# Calculate the statistics for the "Attraction Index" column
mean_attraction_index = df_with_r1closing['Attraction Index'].mean()
std_attraction_index = df_with_r1closing['Attraction Index'].std()
min_attraction_index = df_with_r1closing['Attraction Index'].min()
max_attraction_index = df_with_r1closing['Attraction Index'].max()

# Display the calculated statistics
print(f"Mean Attraction Index: {mean_attraction_index}")
print(f"Standard Deviation of Attraction Index: {std_attraction_index}")
print(f"Minimum Attraction Index: {min_attraction_index}")
print(f"Maximum Attraction Index: {max_attraction_index}")

# Display clusters and their corresponding attraction indexes
cluster_attraction = df_with_r1closing.groupby('Cluster')['Attraction Index'].mean()
print("Clusters and Their Corresponding Attraction Indexes:")
for cluster, attraction_index in cluster_attraction.items():
    print(f"Cluster {cluster}: Attraction Index {attraction_index:.2f}")

merged_df.to_csv("Attraction_Index_AllIndia_OPNO_file.csv")

